{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1541811929334,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "XOkBF0K6P6MC",
    "outputId": "28491ef6-b752-4f09-a797-6d7a4af022ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.optimizers import RMSprop\n",
    "from google.colab import drive\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27779,
     "status": "ok",
     "timestamp": 1541811957994,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "dX7qrncTRKN0",
    "outputId": "c3de5591-d3d1-44c6-b2eb-6c44d603a7b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iek9QSARq1L"
   },
   "outputs": [],
   "source": [
    "file_path = \"/content/gdrive/My Drive/anly590-datasets/shakespeare.txt\"\n",
    "\n",
    "with open(file_path,\"r\") as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ie2LtLF4Vv6A"
   },
   "source": [
    "We've loaded our Shakespeare text, let's take a look at a random snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1541815312567,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "LVFmTUsGWePe",
    "outputId": "293906af-e47c-4f89-9856-283707adc1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lies i' the second chamber?\n",
      "  LADY MACBETH. Donalbain.\n",
      "  MACBETH. This is a sorry sight.           [Looks on his hands.\n",
      "  LADY MACBETH. A foolish thought, to say a sorry sight.\n",
      "  MACBETH. There's one did laugh in 's sleep, and one cried,\n",
      "      \"Murther!\"\n",
      "    That they did wake each other. I stood and heard them,\n",
      "    But they did say their prayers and address'd them\n",
      "    Again to sleep.\n",
      "  LADY MACB\n"
     ]
    }
   ],
   "source": [
    "print(text[31600:32000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLXQHFUsW0xu"
   },
   "source": [
    "We need to convert our text into numeric arrays, the next several blocks accomplish this.\n",
    "\n",
    "First, we'll create a mapping between characters and their numeric index. We'll also create the reverse mapping, which is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1541811961995,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "UkvcQEUASXQG",
    "outputId": "6ba5f988-e63c-4386-c9cc-147f610bd50e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 75\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XexyPZdAXC0p"
   },
   "source": [
    "Next, we'll create a training set of sub-sequences. Remember, we're trying to train a model to be able to predict the next chracter if it is given several characters of a subsequence. So we will create training pairs where each X is a fixed-length subsequences and each Y is the corresponding next letter in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1541811964049,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "ej4RdC76S7RB",
    "outputId": "079d2df8-595a-41ff-c231-09336440dc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 38700\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sub_sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sub_sequences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sub_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1541815609053,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "QVHru3qPWX8Z",
    "outputId": "69e331cb-7aa9-4cef-8a4d-e4deef23e188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sequence):\n",
      " and other Apparitions\n",
      "  Lords, Gentleme\n",
      "\n",
      "(Target Character): \n",
      "n\n"
     ]
    }
   ],
   "source": [
    "k=300\n",
    "print(\"(Sequence):\\n\" + sub_sequences[k])\n",
    "print(\"\\n(Target Character): \\n\" + next_chars[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vD2QxlOAW8zQ"
   },
   "source": [
    "Next we'll create one-hot vectors for our sub-sequences. The tensor we create here will be shaped as (batch_size x seq_length x vocab_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfQRBmiNWehk"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sub_sequences), maxlen, len(chars)), dtype=np.uint8 )\n",
    "Y = np.zeros((len(sub_sequences), len(chars)), dtype=np.uint8)\n",
    "for i, seq in enumerate(sub_sequences):\n",
    "    for t, char in enumerate(seq):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "        Y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1541811974706,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "U4qxjsGDXLtb",
    "outputId": "6987b113-41af-411d-bd5f-8f1e62fe467b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1541731857371,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "423pgyKqXnE_",
    "outputId": "38e5fd04-3637-4463-ab2d-55ffb340830a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dJrr1caYVnI"
   },
   "source": [
    "Our RNN model will be quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95NSRVMpYGAT"
   },
   "outputs": [],
   "source": [
    "char_rnn = Sequential()\n",
    "char_rnn.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "char_rnn.add(Dense(len(chars),activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4xdUMP_Y6iu"
   },
   "outputs": [],
   "source": [
    "\n",
    "char_rnn.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89342,
     "status": "ok",
     "timestamp": 1541813397192,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "KGDTEd0GZFNk",
    "outputId": "150ec6d5-66cd-4a8e-cb15-3ef863ea04d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38700/38700 [==============================] - 9s 226us/step - loss: 0.8576\n",
      "Epoch 2/10\n",
      "38700/38700 [==============================] - 9s 231us/step - loss: 0.8194\n",
      "Epoch 3/10\n",
      "38700/38700 [==============================] - 9s 231us/step - loss: 0.8313\n",
      "Epoch 4/10\n",
      "38700/38700 [==============================] - 9s 231us/step - loss: 0.8129\n",
      "Epoch 5/10\n",
      "38700/38700 [==============================] - 9s 230us/step - loss: 0.7972\n",
      "Epoch 6/10\n",
      "38700/38700 [==============================] - 9s 230us/step - loss: 0.7810\n",
      "Epoch 7/10\n",
      "38700/38700 [==============================] - 9s 231us/step - loss: 0.7728\n",
      "Epoch 8/10\n",
      "38700/38700 [==============================] - 9s 230us/step - loss: 0.7606\n",
      "Epoch 9/10\n",
      "38700/38700 [==============================] - 9s 231us/step - loss: 0.7511\n",
      "Epoch 10/10\n",
      "38700/38700 [==============================] - 9s 230us/step - loss: 0.7348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68804c9710>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_rnn.fit(X,Y, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hhAWPgRX96V"
   },
   "source": [
    "Once we have a trained model, we can simulate new text by making predictions about the next character and then drawing characters in proportion to the predicted probabilities. And then simple repeat that process over and over, each time drawing the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMpJwYSsZSoc"
   },
   "outputs": [],
   "source": [
    "def draw_char(probs):\n",
    "    probs = np.asarray(probs).astype('float64')\n",
    "    if sum(probs) != 1.0:\n",
    "      probs = probs / np.sum(probs)\n",
    "    draw = np.random.choice(range(len(probs)) , p=probs)\n",
    "    return draw\n",
    "\n",
    "def sample_text(model, sample_length=100):\n",
    "    start = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    sequence = text[start: start + maxlen]\n",
    "  \n",
    "    x_preds = np.zeros((sample_length, maxlen, len(chars)))\n",
    "    for i in range(sample_length):\n",
    "        for t, char in enumerate(sequence[-maxlen:]):\n",
    "            x_preds[i, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(np.expand_dims(x_preds[i,:,:], axis=0), verbose=0)[0]\n",
    "        next_index = draw_char(preds)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sequence += next_char\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHD5iDlHayL7"
   },
   "outputs": [],
   "source": [
    "sim = sample_text(char_rnn,sample_length=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1541814414433,
     "user": {
      "displayName": "Keegan Hines",
      "photoUrl": "",
      "userId": "14251275254080316358"
     },
     "user_tz": 300
    },
    "id": "bOP0ljRtOEmp",
    "outputId": "9f545999-a610-4d7a-f7c4-aa07fc320b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y Macbeth\n",
      "  An English Doctor\n",
      "  A Scottim.\n",
      "\n",
      "  MACDUFF. All bone thee we fwar, it that know stain,\n",
      "    In us my ak- Eranul. and hid and yet\n",
      "    God note that I scall vinquowle?\n",
      "  MACBETH. The ste the my thom grise.\n",
      "  MACBETH. With an ERrigh of Now, Or camp, the suff,\n",
      "   MAcrot three a caull hus 'ect, and ention\n",
      "    That suve a catit their hell and hong,\n",
      "    As portinige Come, scoll, \"Your yours cattle;\n",
      "    More, mar burst the King;\n",
      "    Not is trabsped and Dunsinanes, ang lith,\n",
      "    And loodunienters and Indights 'ever mb.\n",
      "    I dight th\n"
     ]
    }
   ],
   "source": [
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aj4kXg4BTbOc"
   },
   "source": [
    "Notice that we can do pretty well to learn the typical statistical patterns of this text and then simulate new text that appears to be very similar to legitimate Shakespeare. \n",
    "\n",
    "But just a caution - we can also do pretty well with a much simpler method (Markov model): http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139\n",
    "\n",
    "So the lesson is to try something simple before jumping right in to deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyI5UtXYVr2U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CharRNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
